I have worked on an image dataset on flower classification to understand fine-tuning and scaling. 
I use EfficientNet, a convolutional neural network architecture, and a scaling method that uniformly scales all dimensions of depth/width/resolution using a compound coefficient. It is based on a compound coefficient Ï• to uniformly scale network width, depth, and resolution in a principled way.
The base EfficientNet-B0 network is based on the inverted bottleneck residual blocks of MobileNetV2, in addition to squeeze-and-excitation blocks. EfficientNet achieves state-of-the-art accuracy on ImageNet and other image classification tasks with significantly fewer parameters than previous models

The EfficientNet scaling method differs from usual practice by consistently scaling the network width, depth, and resolution using a predetermined set of scaling coefficients, instead of arbitrarily scaling these elements. To illustrate, if we desire to utilize 2N times additional computational resources, we can straightforwardly augment the network depth by alphaN, width by betaN, and image size by gammaN. Here, alpha, beta, and gamma are fixed coefficients obtained using a tiny grid search on the initial compact model.
